{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 14.688249,
      "end_time": "2021-02-28T04:18:03.220734",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-02-28T04:17:48.532485",
      "version": "2.2.2"
    },
    "colab": {
      "name": "Wildfire_Ignition_Point_predictor.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10K920/Wildfire-IgnitionPoint-Predictor/blob/main/Wildfire_Ignition_Point_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-02-28T04:17:55.507721Z",
          "iopub.status.busy": "2021-02-28T04:17:55.506913Z",
          "iopub.status.idle": "2021-02-28T04:18:02.299768Z",
          "shell.execute_reply": "2021-02-28T04:18:02.300613Z"
        },
        "papermill": {
          "duration": 6.801616,
          "end_time": "2021-02-28T04:18:02.301107",
          "exception": false,
          "start_time": "2021-02-28T04:17:55.499491",
          "status": "completed"
        },
        "tags": [],
        "id": "7GxYkYezA4hc",
        "outputId": "5949da40-3ddd-4b76-ccfc-3124ff5089f8"
      },
      "source": [
        "# 445449, edward.kang@wustl.edu, Kang, Edward (Yu Sung)\n",
        "# 431147, f.moon@wustl.edu, Moon, Frank\n",
        "# 435472, lee.c@wustl.edu, Lee, Chang Hi\n",
        "# 444516, kang.w@wustl.edu, Kang, Won Young\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "        \n",
        "# Read the Data \n",
        "train = pd.read_csv('../input/wustl-cse517a-sp21-milestone1/train.csv')\n",
        "test = pd.read_csv('../input/wustl-cse517a-sp21-milestone1/test.csv')\n",
        "\n",
        "# Create target array for training\n",
        "train_y = train.Horizontal_Distance_To_Fire_Points\n",
        "\n",
        "# Preprocessing the data / Decoding Soil_Type\n",
        "train['Climatic_Zone'] = train.apply(lambda row: int(str(row.Soil_Type)[0]), axis = 1) # extract the first digit\n",
        "train['Geologic'] = train.apply(lambda row: int(str(row.Soil_Type)[1]), axis = 1) # extract the second digit \n",
        "test['Climatic_Zone'] = test.apply(lambda row: int(str(row.Soil_Type)[0]), axis = 1)\n",
        "test['Geologic'] = test.apply(lambda row: int(str(row.Soil_Type)[1]), axis = 1)\n",
        "\n",
        "# normalize data \n",
        "cols_to_normalize = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', \n",
        "                     'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', \n",
        "                     'Hillshade_Noon', 'Hillshade_3pm']\n",
        "train[cols_to_normalize] = StandardScaler().fit_transform(train[cols_to_normalize])\n",
        "test[cols_to_normalize] = StandardScaler().fit_transform(test[cols_to_normalize])\n",
        "\n",
        "# One-hot encoding Climatic_Zone and Geologic \n",
        "Climatic_Zone_train = pd.get_dummies(train.Climatic_Zone,drop_first=True, prefix='CZ') # drop the first one to prevent multicolinearity\n",
        "Climatic_Zone_test = pd.get_dummies(test.Climatic_Zone, drop_first=True, prefix='CZ')\n",
        "Geologic_train = pd.get_dummies(train.Geologic, drop_first=True,prefix='GEO')\n",
        "Geologic_test = pd.get_dummies(test.Geologic, drop_first=True, prefix='GEO')\n",
        "hot_train = pd.concat([train, Climatic_Zone_train, Geologic_train], axis = 1)\n",
        "hot_test = pd.concat([test, Climatic_Zone_test, Geologic_test], axis = 1)\n",
        "hot_train = hot_train.drop(columns =['Soil_Type', 'Climatic_Zone', 'Geologic']) # remove used columns\n",
        "hot_test = hot_test.drop(columns = ['Soil_Type', 'Climatic_Zone', 'Geologic'])\n",
        "\n",
        "# Create training data \n",
        "predictor_cols = list(hot_train.columns)\n",
        "predictor_cols = [e for e in predictor_cols if e not in ('Horizontal_Distance_To_Fire_Points', 'ID')]\n",
        "train_X = hot_train[predictor_cols]\n",
        "\n",
        "# Train the model using GDBoost\n",
        "reg = GradientBoostingRegressor(random_state=0, n_estimators=300, loss='ls')\n",
        "reg.fit(train_X, train_y)\n",
        "\n",
        "# Make Predictions\n",
        "test_X = hot_test[predictor_cols]\n",
        "predicted_distances = reg.predict(test_X)\n",
        "\n",
        "# Preparing submission file\n",
        "my_submission = pd.DataFrame({'Id': test.ID, 'Horizontal_Distance_To_Fire_Points': predicted_distances})\n",
        "my_submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Calculate in-sample error\n",
        "RMSE2 = mean_squared_error(reg.predict(train_X), train_y, squared=False)\n",
        "print('RMSE ', RMSE2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/input/wustl-cse517a-sp21-milestone1/sample_submission.csv\n",
            "/kaggle/input/wustl-cse517a-sp21-milestone1/train.csv\n",
            "/kaggle/input/wustl-cse517a-sp21-milestone1/test.csv\n",
            "RMSE  564.6284733509643\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}